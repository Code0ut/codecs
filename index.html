<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Bluuey UI â€“ Sidebar Navigation</title>

<link rel="stylesheet" href="style.css"> </head> <body> <h1>Hello, GitHub Pages!</h1> <p>This is my first deployed site.</p> 
</head>

<body>

<div class="sidebar">
    <h2>Bluuey UI</h2>
    <a href="#intro">Introduction</a>
    <a href="#para1">Paragraph 1</a>
    <a href="#para2">Paragraph 2</a>
    <a href="#code1">WAV Analyzer Code</a>
    <a href="#code2">CSS Code</a>
    <a href="#code3">JavaScript Code</a>
</div>

<div class="content">

    <section id="intro">
        <h1>Introduction</h1>
        <p>
            This page documents a Python-based WAV file analyzer with
            metadata extraction, signal analysis, spectral features,
            and visualization.
        </p>
    </section>

    <section id="code1">
        <h1>deDaydetails</h1>
        <pre><code>
            Weekly Internship Report
Pune Vidyarthi Grihaâ€™s College of Engineering, Technology and Management
Name: Omkar Kalburgi		Roll No: 		Branch: T.E. Artificial Intelligence & Data Science
Internship Domain: Artificial Intelligence & Data Science    Organization Name: 
Week Number: Week 1		Reporting Mentor:

            Day-wise Work Details
Day 1: Introduction to Company Policies
On the first day of the internship, I was introduced to the companyâ€™s policies, rules, and regulations. The session covered organizational ethics, professional conduct, safety guidelines, confidentiality norms, and attendance requirements. This helped me understand the expected standards of behaviour and discipline within the organization.

Day 2: Introduction to Company Premises and Departments
The second day involved a guided tour of the company premises. I was introduced to various departments and their respective roles and responsibilities. This provided an overall understanding of the organizational structure and how different departments collaborate to achieve common objectives.

Day 3: Team Introduction and Interaction
On the third day, I met my internship team and was formally introduced to team members and mentors. The roles of each team member were explained, along with the workflow followed by the team. This interaction helped me understand teamwork, communication flow, and coordination within the organization.

Day 4: Introduction to Problem Statement (PS)
On the fourth day, I was introduced to the problem statement (PS) assigned for the internship. The basics of the problem were explained. This day helped me gain an initial understanding of the project and its expected outcomes.

Day 5: System Setup and Hardware/Software Configuration
The fifth day focused on setting up the required systems for internship work. Necessary hardware checks were performed, and essential software tools were installed and configured. This ensured that all technical requirements were met for smooth execution of tasks during the internship period.


Challenges Faced & Solutions
â€¢	Initial difficulty in setting up hardware and software configuration
Solution: I was able to achieve desired hardware and software configuration by communicating with one of my seniors.
â€¢	Unable to achieve an clear understanding of aim and objectives for the problem statement.

Studentâ€™s Reflection

This week helped me understand the working environment and professional behaviour followed in industries, along with gaining an overall understanding of how large-scale industries operate. The exposure provided valuable insight into industrial culture, coordination between departments, and structured work processes.




Student Signature: _______________________
Date: ___ / ___ / 2025










Internship Supervisor / Mentor Signature: _______________________
Date: ___ / ___ / 2025

</code></pre>
    </section>
    <section id="code1">
        <h1>WAV Analyzer â€“ Python Code</h1>
        <pre><code>import numpy as np
import librosa
import scipy.signal as signal
from scipy.ndimage import label,find_objects
import noisereduce as nr
class HydrophonePulseAnalyzer:

    def __init__(self, wav_path):
        self.wav_path = wav_path
        self.y = None
        self.sr = None
        self.envelope = None
        self.pulses = []

    def load_audio(self):
        self.y, self.sr = librosa.load(self.wav_path, sr=None, mono=True)
        self.y = nr.reduce_noise(y=self.y, sr=self.sr)
    def bandpass_filter(self, low=50, high=5000, order=4):
        nyq = 0.5 * self.sr
        b, a = signal.butter(order, [low/nyq, high/nyq], btype='band')
        self.y = signal.filtfilt(b, a, self.y)

    def compute_envelope(self):
        analytic_signal = signal.hilbert(self.y)
        self.envelope = np.abs(analytic_signal)

    def detect_pulses(self, threshold_factor=3):
        noise_floor = np.mean(self.envelope)
        threshold = threshold_factor * noise_floor

        binary = self.envelope > threshold

        labeled, num = label(binary)
        regions = find_objects(labeled)

        for region in regions:
            start = region[0].start
            end = region[0].stop
            duration = (end - start) / self.sr
            self.pulses.append({
                "start_sample": start,
                "end_sample": end,
                "duration_sec": duration
            })

    def get_pulse_durations(self):
        return [p["duration_sec"] for p in self.pulses]
    def get_pulse_frequencies(self):
        frequencies = []

        for pulse in self.pulses:
            start = pulse["start_sample"]
            end = pulse["end_sample"]

            pulse_signal = self.y[start:end]

            if len(pulse_signal) < 10:
                frequencies.append(0)
                continue

            window = np.hanning(len(pulse_signal))
            pulse_signal = pulse_signal * window

            fft_vals = np.abs(np.fft.rfft(pulse_signal))
            freqs = np.fft.rfftfreq(len(pulse_signal), 1 / self.sr)

            dominant_freq = freqs[np.argmax(fft_vals)]
            frequencies.append(dominant_freq)

            pulse["frequency_hz"] = dominant_freq

        return frequencies

    def merge_close_pulses(self, merge_gap_sec=0.02):
        if not self.pulses:
            return

        merged = []
        merge_gap_samples = int(merge_gap_sec * self.sr)

        current = self.pulses[0]

        for next_pulse in self.pulses[1:]:
            gap = next_pulse["start_sample"] - current["end_sample"]

            if gap <= merge_gap_samples:
                current["end_sample"] = next_pulse["end_sample"]
                current["duration_sec"] = (
                    current["end_sample"] - current["start_sample"]
                ) / self.sr
            else:
                merged.append(current)
                current = next_pulse

        merged.append(current)
        self.pulses = merged


    def get_pulse_snr(self, noise_margin_sec=0.05):
        snrs = []

        for pulse in self.pulses:
            start = pulse["start_sample"]
            end = pulse["end_sample"]
            pulse_len = end - start

            noise_len = int(noise_margin_sec * self.sr)
            noise_start = max(0, start - noise_len - pulse_len)
            noise_end = max(0, start - noise_len)

            signal_segment = self.y[start:end]
            noise_segment = self.y[noise_start:noise_end]

            if len(noise_segment) == 0 or len(signal_segment) == 0:
                snrs.append(None)
                pulse["snr_db"] = None
                continue

            signal_power = np.mean(signal_segment ** 2)
            noise_power = np.mean(noise_segment ** 2)

            if noise_power == 0:
                snr_db = np.inf
            else:
                snr_db = 10 * np.log10(signal_power / noise_power)

            snrs.append(snr_db)
            pulse["snr_db"] = snr_db

        return snrs

# 2ï¸âƒ£ Identify the Signal Type (MOST IMPORTANT)
# Source	Typical Frequency Band
# Ship propeller (DEMON)	1â€“200 Hz
# Engine machinery	50â€“1000 Hz
# Sonar pings	1â€“10 kHz
# Whale vocalizations	20â€“3000 Hz
# Snapping shrimp	2â€“20 kHz

# ðŸ‘‰ You are analyzing humpback whale, so:

# Expected band: 20 Hz â€“ 3 kHz

# 3ï¸âƒ£ Practical Method to Choose Lowcut & Highcut
# Step-1: Look at the spectrum (mandatory)
# import matplotlib.pyplot as plt
# import librosa.display

# D = np.abs(np.fft.rfft(analyzer.y))
# freqs = np.fft.rfftfreq(len(analyzer.y), 1/analyzer.sr)

# plt.plot(freqs, 20*np.log10(D + 1e-12))
# plt.xlim(0, 5000)
# plt.xlabel("Frequency (Hz)")
# plt.ylabel("Magnitude (dB)")
# plt.show()


# ðŸ‘‰ Visually observe:

# Where energy rises above noise

# Where it drops back to noise
analyzer = HydrophonePulseAnalyzer("humpback_whale.wav")

analyzer.load_audio()
analyzer.bandpass_filter(low=100, high=3000)  # adjust based on target
analyzer.compute_envelope()
analyzer.detect_pulses(threshold_factor=4)

durations = analyzer.get_pulse_durations()
pulse_freqs = analyzer.get_pulse_frequencies()
print("Pulse durations (seconds):")
# for d in durations:
#     print(round(d, 4))
for i in range(len(durations)):
    print(
        f"Pulse {i+1}: "
        f"Duration = {durations[i]:.4f} s, "
        f"Frequency = {pulse_freqs[i]:.1f} Hz"
    )</code></pre>
    </section>

    <section id="code2">
        <h1>cdcd Code Example</h1>
        <pre><code>import numpy as np
import scipy.signal as signal

def compute_psd(y, sr, nperseg=4096):
    freqs, psd = signal.welch(
        y,
        fs=sr,
        window='hann',
        nperseg=nperseg,
        scaling='density'
    )
    return freqs, psd

def estimate_noise_floor(psd):
    return np.median(psd)

def detect_signal_band(freqs, psd, noise_floor, factor=6):
    mask = psd > (noise_floor * factor)
    signal_freqs = freqs[mask]

    if len(signal_freqs) == 0:
        return None, None

    lowcut = signal_freqs[0]
    highcut = signal_freqs[-1]

    return lowcut, highcut

def pad_band(lowcut, highcut, sr, pad_ratio=0.1):
    bandwidth = highcut - lowcut
    low = max(1.0, lowcut - bandwidth * pad_ratio)
    high = min(0.45 * sr, highcut + bandwidth * pad_ratio)
    return low, high

def auto_select_band(y, sr, factor=6):
    freqs, psd = compute_psd(y, sr)
    noise_floor = estimate_noise_floor(psd)

    lowcut, highcut = detect_signal_band(freqs, psd, noise_floor, factor)

    if lowcut is None:
        raise ValueError("No dominant signal detected")

    lowcut, highcut = pad_band(lowcut, highcut, sr)

    return lowcut, highcut

y, sr = librosa.load("hydrophone.wav", sr=None)

lowcut, highcut = auto_select_band(y, sr)

print(f"Auto-selected band: {lowcut:.1f} Hz â€“ {highcut:.1f} Hz")

y_filtered = bandpass_filter(y, sr, lowcut, highcut)

import matplotlib.pyplot as plt

def plot_psd(freqs, psd, lowcut, highcut):
    plt.semilogy(freqs, psd)
    plt.axvline(lowcut, color='r')
    plt.axvline(highcut, color='r')
    plt.xlabel("Frequency (Hz)")
    plt.ylabel("PSD")
    plt.title("PSD with Auto-Selected Band")
    plt.show()
</code></pre>
    </section>

    <section id="code3">
        <h1>JavaScript Code Example</h1>
        <pre><code>import numpy as np
import librosa
import scipy.signal as signal
import matplotlib.pyplot as plt
from scipy.ndimage import median_filter

class LofarDemonAnalyzer:

    def __init__(self, wav_path):
        self.wav_path = wav_path
        self.y = None
        self.sr = None

        self.lowcut = None
        self.highcut = None

        self.lofar_spectrogram = None
        self.demon_freqs = None
        self.demon_spectrum = None

    def load_audio(self):
        self.y, self.sr = librosa.load(self.wav_path, sr=None, mono=True)

    def _compute_psd(self, nperseg=4096):
        freqs, psd = signal.welch(
            self.y,
            fs=self.sr,
            window="hann",
            nperseg=nperseg,
            scaling="density"
        )
        return freqs, psd

    def auto_select_band(self, factor=6):
        freqs, psd = self._compute_psd()
        noise_floor = np.median(psd)

        mask = psd > noise_floor * factor
        signal_freqs = freqs[mask]

        if len(signal_freqs) == 0:
            raise ValueError("No dominant signal detected")

        low = signal_freqs[0]
        high = signal_freqs[-1]

        bw = high - low
        self.lowcut = max(1.0, low - 0.1 * bw)
        self.highcut = min(0.45 * self.sr, high + 0.1 * bw)

    def _bandpass_filter(self, low, high, order=4):
        nyq = 0.5 * self.sr
        b, a = signal.butter(order, [low/nyq, high/nyq], btype='band')
        return signal.filtfilt(b, a, self.y)

    def compute_lofar(self, n_fft=2048, hop=1024):
        y_bp = self._bandpass_filter(self.lowcut, self.highcut)

        S = np.abs(librosa.stft(y_bp, n_fft=n_fft, hop_length=hop))
        S_db = librosa.amplitude_to_db(S, ref=np.max)

        self.lofar_spectrogram = median_filter(S_db, size=(3, 3))

    def compute_demon(self, demon_low=5, demon_high=200):
        y_bp = self._bandpass_filter(demon_low, demon_high)

        envelope = np.abs(signal.hilbert(y_bp))

        spectrum = np.abs(np.fft.rfft(envelope))
        freqs = np.fft.rfftfreq(len(envelope), 1 / self.sr)

        self.demon_freqs = freqs
        self.demon_spectrum = spectrum

    def plot_lofar(self):
        plt.figure(figsize=(10, 4))
        librosa.display.specshow(
            self.lofar_spectrogram,
            sr=self.sr,
            x_axis="time",
            y_axis="hz"
        )
        plt.colorbar(label="dB")
        plt.title("LOFAR Spectrogram")
        plt.tight_layout()
        plt.show()

    def plot_demon(self):
        plt.figure(figsize=(8, 4))
        plt.plot(self.demon_freqs, self.demon_spectrum)
        plt.xlim(0, 200)
        plt.xlabel("Frequency (Hz)")
        plt.ylabel("Amplitude")
        plt.title("DEMON Spectrum")
        plt.tight_layout()
        plt.show()


analyzer = LofarDemonAnalyzer("hydrophone.wav")

analyzer.load_audio()
analyzer.auto_select_band()

analyzer.compute_lofar()
analyzer.compute_demon()

analyzer.plot_lofar()
analyzer.plot_demon()

</code></pre>
    </section>

    <footer>
        Â© 2025 Bluuey UI â€“ WAV Analyzer Documentation
    </footer>

</div>
<!-- Link to JavaScript --> <script src="script.js"></script>
</body>
</html>
