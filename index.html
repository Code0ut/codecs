<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Bluuey UI â€“ Sidebar Navigation</title>

<link rel="stylesheet" href="style.css"> </head> <body> <h1>Hello, GitHub Pages!</h1> <p>This is my first deployed site.</p> 
</head>

<body>

<div class="sidebar">
    <h2>Bluuey UI</h2>
    <a href="#intro">Introduction</a>
    <a href="#para1">Paragraph 1</a>
    <a href="#para2">Paragraph 2</a>
    <a href="#code1">WAV Analyzer Code</a>
    <a href="#code2">CSS Code</a>
    <a href="#code3">JavaScript Code</a>
</div>

<div class="content">

    <section id="intro">
        <h1>Introduction</h1>
        <p>
            This page documents a Python-based WAV file analyzer with
            metadata extraction, signal analysis, spectral features,
            and visualization.
        </p>
    </section>

    <section id="code1">
        <h1>deDaydetails</h1>
        <pre><code>
            Weekly Internship Report
Pune Vidyarthi Grihaâ€™s College of Engineering, Technology and Management
Name: Omkar Kalburgi		Roll No: 		Branch: T.E. Artificial Intelligence & Data Science
Internship Domain: Artificial Intelligence & Data Science    Organization Name: 
Week Number: Week 1		Reporting Mentor:

            Day-wise Work Details
Day 1: Introduction to Company Policies
On the first day of the internship, I was introduced to the companyâ€™s policies, rules, and regulations. The session covered organizational ethics, professional conduct, safety guidelines, confidentiality norms, and attendance requirements. This helped me understand the expected standards of behaviour and discipline within the organization.

Day 2: Introduction to Company Premises and Departments
The second day involved a guided tour of the company premises. I was introduced to various departments and their respective roles and responsibilities. This provided an overall understanding of the organizational structure and how different departments collaborate to achieve common objectives.

Day 3: Team Introduction and Interaction
On the third day, I met my internship team and was formally introduced to team members and mentors. The roles of each team member were explained, along with the workflow followed by the team. This interaction helped me understand teamwork, communication flow, and coordination within the organization.

Day 4: Introduction to Problem Statement (PS)
On the fourth day, I was introduced to the problem statement (PS) assigned for the internship. The basics of the problem were explained. This day helped me gain an initial understanding of the project and its expected outcomes.

Day 5: System Setup and Hardware/Software Configuration
The fifth day focused on setting up the required systems for internship work. Necessary hardware checks were performed, and essential software tools were installed and configured. This ensured that all technical requirements were met for smooth execution of tasks during the internship period.


Challenges Faced & Solutions
â€¢	Initial difficulty in setting up hardware and software configuration
Solution: I was able to achieve desired hardware and software configuration by communicating with one of my seniors.
â€¢	Unable to achieve an clear understanding of aim and objectives for the problem statement.

Studentâ€™s Reflection

This week helped me understand the working environment and professional behaviour followed in industries, along with gaining an overall understanding of how large-scale industries operate. The exposure provided valuable insight into industrial culture, coordination between departments, and structured work processes.




Student Signature: _______________________
Date: ___ / ___ / 2025










Internship Supervisor / Mentor Signature: _______________________
Date: ___ / ___ / 2025

</code></pre>
    </section>
    <section id="code1">
        <h1>WAV Analyzer â€“ Python Code</h1>
        <pre><code>import numpy as np
import librosa
import scipy.signal as signal
from scipy.ndimage import label,find_objects
import noisereduce as nr
class HydrophonePulseAnalyzer:

    def __init__(self, wav_path):
        self.wav_path = wav_path
        self.y = None
        self.sr = None
        self.envelope = None
        self.pulses = []

    def load_audio(self):
        self.y, self.sr = librosa.load(self.wav_path, sr=None, mono=True)
        self.y = nr.reduce_noise(y=self.y, sr=self.sr)
    def bandpass_filter(self, low=50, high=5000, order=4):
        nyq = 0.5 * self.sr
        b, a = signal.butter(order, [low/nyq, high/nyq], btype='band')
        self.y = signal.filtfilt(b, a, self.y)

    def compute_envelope(self):
        analytic_signal = signal.hilbert(self.y)
        self.envelope = np.abs(analytic_signal)

    def detect_pulses(self, threshold_factor=3):
        noise_floor = np.mean(self.envelope)
        threshold = threshold_factor * noise_floor

        binary = self.envelope > threshold

        labeled, num = label(binary)
        regions = find_objects(labeled)

        for region in regions:
            start = region[0].start
            end = region[0].stop
            duration = (end - start) / self.sr
            self.pulses.append({
                "start_sample": start,
                "end_sample": end,
                "duration_sec": duration
            })

    def get_pulse_durations(self):
        return [p["duration_sec"] for p in self.pulses]
    def get_pulse_frequencies(self):
        frequencies = []

        for pulse in self.pulses:
            start = pulse["start_sample"]
            end = pulse["end_sample"]

            pulse_signal = self.y[start:end]

            if len(pulse_signal) < 10:
                frequencies.append(0)
                continue

            window = np.hanning(len(pulse_signal))
            pulse_signal = pulse_signal * window

            fft_vals = np.abs(np.fft.rfft(pulse_signal))
            freqs = np.fft.rfftfreq(len(pulse_signal), 1 / self.sr)

            dominant_freq = freqs[np.argmax(fft_vals)]
            frequencies.append(dominant_freq)

            pulse["frequency_hz"] = dominant_freq

        return frequencies

    def get_pulse_snr(self, noise_margin_sec=0.05):
        snrs = []

        for pulse in self.pulses:
            start = pulse["start_sample"]
            end = pulse["end_sample"]
            pulse_len = end - start

            noise_len = int(noise_margin_sec * self.sr)
            noise_start = max(0, start - noise_len - pulse_len)
            noise_end = max(0, start - noise_len)

            signal_segment = self.y[start:end]
            noise_segment = self.y[noise_start:noise_end]

            if len(noise_segment) == 0 or len(signal_segment) == 0:
                snrs.append(None)
                pulse["snr_db"] = None
                continue

            signal_power = np.mean(signal_segment ** 2)
            noise_power = np.mean(noise_segment ** 2)

            if noise_power == 0:
                snr_db = np.inf
            else:
                snr_db = 10 * np.log10(signal_power / noise_power)

            snrs.append(snr_db)
            pulse["snr_db"] = snr_db

        return snrs

# 2ï¸âƒ£ Identify the Signal Type (MOST IMPORTANT)
# Source	Typical Frequency Band
# Ship propeller (DEMON)	1â€“200 Hz
# Engine machinery	50â€“1000 Hz
# Sonar pings	1â€“10 kHz
# Whale vocalizations	20â€“3000 Hz
# Snapping shrimp	2â€“20 kHz

# ðŸ‘‰ You are analyzing humpback whale, so:

# Expected band: 20 Hz â€“ 3 kHz

# 3ï¸âƒ£ Practical Method to Choose Lowcut & Highcut
# Step-1: Look at the spectrum (mandatory)
# import matplotlib.pyplot as plt
# import librosa.display

# D = np.abs(np.fft.rfft(analyzer.y))
# freqs = np.fft.rfftfreq(len(analyzer.y), 1/analyzer.sr)

# plt.plot(freqs, 20*np.log10(D + 1e-12))
# plt.xlim(0, 5000)
# plt.xlabel("Frequency (Hz)")
# plt.ylabel("Magnitude (dB)")
# plt.show()


# ðŸ‘‰ Visually observe:

# Where energy rises above noise

# Where it drops back to noise
analyzer = HydrophonePulseAnalyzer("humpback_whale.wav")

analyzer.load_audio()
analyzer.bandpass_filter(low=100, high=3000)  # adjust based on target
analyzer.compute_envelope()
analyzer.detect_pulses(threshold_factor=4)

durations = analyzer.get_pulse_durations()
pulse_freqs = analyzer.get_pulse_frequencies()
print("Pulse durations (seconds):")
# for d in durations:
#     print(round(d, 4))
for i in range(len(durations)):
    print(
        f"Pulse {i+1}: "
        f"Duration = {durations[i]:.4f} s, "
        f"Frequency = {pulse_freqs[i]:.1f} Hz"
    )

</code></pre>
    </section>

    <section id="code2">
        <h1>cdcd Code Example</h1>
        <pre><code>import numpy as np
from scipy import signal
import matplotlib.pyplot as plt
import librosa

x,fs=librosa.load('humpback_whale.wav', sr=6000)

n_fft = 2048
nperseg = 2048        # window length
noverlap = nperseg//2 # 50% overlap
window = signal.windows.hann(nperseg, sym=False)

f, t, Sxx = signal.spectrogram(
    x,
    fs=fs,
    window=window,
    nperseg=nperseg,
    noverlap=noverlap,
    nfft=n_fft,
    detrend=False,
    scaling='density',   # gives PSD (V^2/Hz) style units
    mode='magnitude'     # or 'psd' depending on use
)

# Optionally restrict to low-frequency band, e.g. 0â€“1000 Hz
f_max = 1000
idx = f <= f_max
f = f[idx]
Sxx = Sxx[idx, :]

# Convert magnitude to dB for display
eps = 1e-12
Sxx_db = 20 * np.log10(Sxx + eps)

plt.figure(figsize=(8, 4))
plt.pcolormesh(t, f, Sxx_db, shading='gouraud', cmap='viridis')
plt.ylabel('Frequency [Hz]')
plt.xlabel('Time [s]')
plt.title('LOFARgram')
plt.colorbar(label='Level [dB]')
plt.tight_layout()
plt.show()

# Example: simple per-frequency normalization for ML
Sxx_db_norm = (Sxx_db - Sxx_db.mean(axis=1, keepdims=True)) / \
               (Sxx_db.std(axis=1, keepdims=True) + 1e-6)

# Sxx_db_norm can now be used as input feature (e.g., to a CNN)

</code></pre>
    </section>

    <section id="code3">
        <h1>JavaScript Code Example</h1>
        <pre><code>import numpy as np
from scipy import signal
import matplotlib.pyplot as plt
import librosa
x,fs=librosa.load("humpback_whale.wav",sr=None)
print(f"Loaded signal with {len(x)} samples at {fs} Hz")
import numpy as np
from scipy import signal

def third_octave_centers(fmin=20, fmax=20000, ref_fc=1000):
    n_low = int(np.ceil(3 * np.log2(fmin / ref_fc)))
    n_high = int(np.floor(3 * np.log2(fmax / ref_fc)))
    n = np.arange(n_low, n_high + 1)
    return ref_fc * (2 ** (n / 3.0))

def design_third_octave_filters(fc, fs, order=4):
    filters = []
    nyq = fs / 2.0
    bw_factor = 2 ** (1/6)  # 1/6 octave from center to edge

    for f_center in fc:
        f_low = f_center / bw_factor
        f_high = f_center * bw_factor

        # Skip bands that go outside (0, Nyquist)
        if f_low <= 0 or f_high >= nyq:
            continue

        low = f_low / nyq
        high = f_high / nyq

        # Extra safety check
        if not (0 < low < high < 1):
            continue

        b, a = signal.butter(order, [low, high], btype='band')
        filters.append((b, a, f_center))

    return filters

fc = third_octave_centers(20, fs/2) 

filters = design_third_octave_filters(fc, fs)

# Example signal (replace with your sonar data)
t = np.arange(0, 10, 1/fs)
x = np.random.randn(len(t))  # white noise example

# Filter signal through each band
band_signals = []
band_rms = []
valid_fc = []
for b, a, f_center in filters:
    # Filter the signal
    y_band = signal.filtfilt(b, a, x)  # zero-phase filtering
    
    # Compute RMS power in this band
    rms = np.sqrt(np.mean(y_band**2))
    band_signals.append(y_band)
    band_rms.append(rms)
    valid_fc.append(f_center)
band_rms_db = 20 * np.log10(np.array(band_rms) + 1e-12)
valid_fc = np.array(valid_fc)
plt.figure(figsize=(10, 6))
plt.semilogx(valid_fc, band_rms_db, 'o-', linewidth=2)
plt.xlabel('Frequency [Hz]')
plt.ylabel('Level [dB re 1 V RMS]')
plt.title('1/3-Octave Band Spectrum')
plt.grid(True, which='both')
plt.xlim([20, fs/2])
plt.ylim([-60, 0])
plt.show()

def third_octave_analysis(x, fs, fmin=20, fmax=None):
    """Complete 1/3-octave analysis: returns centers, levels (dB), and band signals."""
    if fmax is None:
        fmax = fs / 2
    fc = third_octave_centers(fmin, fmax)
    filters = design_third_octave_filters(fc, fs)
    
    band_rms = []
    for b, a, f_center in filters:
        y_band = signal.filtfilt(b, a, x)
        rms = np.sqrt(np.mean(y_band**2))
        band_rms.append(rms)
    
    return fc, 20 * np.log10(np.array(band_rms) + 1e-12)

# Usage
fc, levels_db = third_octave_analysis(x, fs)

</code></pre>
    </section>

    <footer>
        Â© 2025 Bluuey UI â€“ WAV Analyzer Documentation
    </footer>

</div>
<!-- Link to JavaScript --> <script src="script.js"></script>
</body>
</html>
