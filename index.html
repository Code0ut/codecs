<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Bluuey UI – Sidebar Navigation</title>

<link rel="stylesheet" href="style.css"> </head> <body> <h1>Hello, GitHub Pages!</h1> <p>This is my first deployed site.</p> 
</head>

<body>

<div class="sidebar">
    <h2>Bluuey UI</h2>
    <a href="#intro">Introduction</a>
    <a href="#para1">Paragraph 1</a>
    <a href="#para2">Paragraph 2</a>
    <a href="#code1">WAV Analyzer Code</a>
    <a href="#code2">CSS Code</a>
    <a href="#code3">JavaScript Code</a>
</div>

<div class="content">

    <section id="intro">
        <h1>Introduction</h1>
        <p>
            This page documents a Python-based WAV file analyzer with
            metadata extraction, signal analysis, spectral features,
            and visualization.
        </p>
    </section>

    <section id="code1">
        <h1>deDaydetails</h1>
        <pre><code>
            Weekly Internship Report
Pune Vidyarthi Griha’s College of Engineering, Technology and Management
Name: Omkar Kalburgi		Roll No: 		Branch: T.E. Artificial Intelligence & Data Science
Internship Domain: Artificial Intelligence & Data Science    Organization Name: 
Week Number: Week 1		Reporting Mentor:

            Day-wise Work Details
Day 1: Introduction to Company Policies
On the first day of the internship, I was introduced to the company’s policies, rules, and regulations. The session covered organizational ethics, professional conduct, safety guidelines, confidentiality norms, and attendance requirements. This helped me understand the expected standards of behaviour and discipline within the organization.

Day 2: Introduction to Company Premises and Departments
The second day involved a guided tour of the company premises. I was introduced to various departments and their respective roles and responsibilities. This provided an overall understanding of the organizational structure and how different departments collaborate to achieve common objectives.

Day 3: Team Introduction and Interaction
On the third day, I met my internship team and was formally introduced to team members and mentors. The roles of each team member were explained, along with the workflow followed by the team. This interaction helped me understand teamwork, communication flow, and coordination within the organization.

Day 4: Introduction to Problem Statement (PS)
On the fourth day, I was introduced to the problem statement (PS) assigned for the internship. The basics of the problem were explained. This day helped me gain an initial understanding of the project and its expected outcomes.

Day 5: System Setup and Hardware/Software Configuration
The fifth day focused on setting up the required systems for internship work. Necessary hardware checks were performed, and essential software tools were installed and configured. This ensured that all technical requirements were met for smooth execution of tasks during the internship period.


Challenges Faced & Solutions
•	Initial difficulty in setting up hardware and software configuration
Solution: I was able to achieve desired hardware and software configuration by communicating with one of my seniors.
•	Unable to achieve an clear understanding of aim and objectives for the problem statement.

Student’s Reflection

This week helped me understand the working environment and professional behaviour followed in industries, along with gaining an overall understanding of how large-scale industries operate. The exposure provided valuable insight into industrial culture, coordination between departments, and structured work processes.




Student Signature: _______________________
Date: ___ / ___ / 2025










Internship Supervisor / Mentor Signature: _______________________
Date: ___ / ___ / 2025

</code></pre>
    </section>
    <section id="code1">
        <h1>WAV Analyzer – Python Code</h1>
        <pre><code># import numpy as np
# import matplotlib.pyplot as plt
# from scipy.io import wavfile
# from scipy.signal import stft
# from mpl_toolkits.mplot3d import Axes3D

# wav_path = "humpback_whale.wav"   # change path

# sr, data = wavfile.read(wav_path)

# if data.ndim > 1:
#     data = data[:, 0]

# f, t, Zxx = stft(data, fs=sr, nperseg=1024)

# magnitude = np.abs(Zxx)

# X, Y = np.meshgrid(t, f)

# fig = plt.figure(figsize=(12, 8))
# ax = fig.add_subplot(111, projection='3d')

# stride = 5
# ax.plot_surface(
#     X[::stride, ::stride],
#     Y[::stride, ::stride],
#     magnitude[::stride, ::stride],
#     cmap='viridis'
# )

# ax.set_xlabel("Time (s)")
# ax.set_ylabel("Frequency (Hz)")
# ax.set_zlabel("Magnitude")

# ax.set_title("3D Waterfall Plot")

# plt.show()

from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm

# Creating dataset
x = np.outer(np.linspace(-3, 3, 32), np.ones(32))
y = x.copy().T
z = np.sin(x**2) + np.cos(y**2)

# ----- Gradient computation -----
dz_dx, dz_dy = np.gradient(z)
grad_mag = np.sqrt(dz_dx**2 + dz_dy**2)

# Normalize gradient for coloring
grad_norm = (grad_mag - grad_mag.min()) / (grad_mag.max() - grad_mag.min())

# Creating figure
fig = plt.figure(figsize=(14, 9))
ax = plt.axes(projection='3d')

# Gradient-colored surface
surf = ax.plot_surface(
    x, y, z,
    facecolors=cm.viridis(grad_norm),
    rstride=1,
    cstride=1,
    linewidth=0,
    antialiased=True
)

# Colorbar (gradient intensity)
mappable = cm.ScalarMappable(cmap=cm.viridis)
mappable.set_array(grad_mag)
fig.colorbar(mappable, ax=ax, shrink=0.6, label="Gradient Magnitude")

ax.set_xlabel("X")
ax.set_ylabel("Y")
ax.set_zlabel("Z")

ax.set_title("3D Gradient Surface Plot")

plt.show()

</code></pre>
    </section>

    <section id="code2">
        <h1>cdcd Code Example</h1>
        <pre><code>import numpy as np
import scipy.signal as signal

def compute_psd(y, sr, nperseg=4096):
    freqs, psd = signal.welch(
        y,
        fs=sr,
        window='hann',
        nperseg=nperseg,
        scaling='density'
    )
    return freqs, psd

def estimate_noise_floor(psd):
    return np.median(psd)

def detect_signal_band(freqs, psd, noise_floor, factor=6):
    mask = psd > (noise_floor * factor)
    signal_freqs = freqs[mask]

    if len(signal_freqs) == 0:
        return None, None

    lowcut = signal_freqs[0]
    highcut = signal_freqs[-1]

    return lowcut, highcut

def pad_band(lowcut, highcut, sr, pad_ratio=0.1):
    bandwidth = highcut - lowcut
    low = max(1.0, lowcut - bandwidth * pad_ratio)
    high = min(0.45 * sr, highcut + bandwidth * pad_ratio)
    return low, high

def auto_select_band(y, sr, factor=6):
    freqs, psd = compute_psd(y, sr)
    noise_floor = estimate_noise_floor(psd)

    lowcut, highcut = detect_signal_band(freqs, psd, noise_floor, factor)

    if lowcut is None:
        raise ValueError("No dominant signal detected")

    lowcut, highcut = pad_band(lowcut, highcut, sr)

    return lowcut, highcut

y, sr = librosa.load("hydrophone.wav", sr=None)

lowcut, highcut = auto_select_band(y, sr)

print(f"Auto-selected band: {lowcut:.1f} Hz – {highcut:.1f} Hz")

y_filtered = bandpass_filter(y, sr, lowcut, highcut)

import matplotlib.pyplot as plt

def plot_psd(freqs, psd, lowcut, highcut):
    plt.semilogy(freqs, psd)
    plt.axvline(lowcut, color='r')
    plt.axvline(highcut, color='r')
    plt.xlabel("Frequency (Hz)")
    plt.ylabel("PSD")
    plt.title("PSD with Auto-Selected Band")
    plt.show()

    import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile
from scipy.signal import spectrogram
from matplotlib import cm

# Load audio
sample_rate, data = wavfile.read("humpback_whale.wav")

if data.ndim > 1:
    data = data[:, 0]

# Spectrogram
frequencies, times, Sxx = spectrogram(data, fs=sample_rate, nperseg=1024)

# dB scale
Sxx_dB = 10 * np.log10((Sxx/1e-6) + 1e-10)

# Meshgrid (THIS is what you were missing)
X, Y = np.meshgrid(times, frequencies)
Z = Sxx_dB

# Gradient for coloring
dz_df, dz_dt = np.gradient(Z)
grad_mag = np.sqrt(dz_df**2 + dz_dt**2)
grad_norm = (grad_mag - grad_mag.min()) / (grad_mag.max() - grad_mag.min())

# Plot
fig = plt.figure(figsize=(14, 9))
ax = fig.add_subplot(111, projection='3d')

ax.plot_surface(
    X, Y, Z,
    facecolors=cm.viridis(grad_norm),
    rstride=6,
    cstride=6,
    linewidth=0,
    antialiased=True
)

# Colorbar
mappable = cm.ScalarMappable(cmap=cm.viridis)
mappable.set_array(grad_mag)
fig.colorbar(mappable, ax=ax, shrink=0.6, label="Gradient Magnitude")

ax.set_xlabel("Time (s)")
ax.set_ylabel("Frequency (Hz)")
ax.set_zlabel("Amplitude (dB)")
ax.set_title("3D Gradient Surface Plot (Spectrogram)")

plt.show()
</code></pre>
    </section>

    <section id="code3">
        <h1>JavaScript Code Example</h1>
        <pre><code>import numpy as np
import librosa
import scipy.signal as signal
import matplotlib.pyplot as plt
from scipy.ndimage import median_filter

class LofarDemonAnalyzer:

    def __init__(self, wav_path):
        self.wav_path = wav_path
        self.y = None
        self.sr = None

        self.lowcut = None
        self.highcut = None

        self.lofar_spectrogram = None
        self.demon_freqs = None
        self.demon_spectrum = None

    def load_audio(self):
        self.y, self.sr = librosa.load(self.wav_path, sr=None, mono=True)

    def _compute_psd(self, nperseg=4096):
        freqs, psd = signal.welch(
            self.y,
            fs=self.sr,
            window="hann",
            nperseg=nperseg,
            scaling="density"
        )
        return freqs, psd

    def auto_select_band(self, factor=6):
        freqs, psd = self._compute_psd()
        noise_floor = np.median(psd)

        mask = psd > noise_floor * factor
        signal_freqs = freqs[mask]

        if len(signal_freqs) == 0:
            raise ValueError("No dominant signal detected")

        low = signal_freqs[0]
        high = signal_freqs[-1]

        bw = high - low
        self.lowcut = max(1.0, low - 0.1 * bw)
        self.highcut = min(0.45 * self.sr, high + 0.1 * bw)

    def _bandpass_filter(self, low, high, order=4):
        nyq = 0.5 * self.sr
        b, a = signal.butter(order, [low/nyq, high/nyq], btype='band')
        return signal.filtfilt(b, a, self.y)

    def compute_lofar(self, n_fft=2048, hop=1024):
        y_bp = self._bandpass_filter(self.lowcut, self.highcut)

        S = np.abs(librosa.stft(y_bp, n_fft=n_fft, hop_length=hop))
        S_db = librosa.amplitude_to_db(S, ref=np.max)

        self.lofar_spectrogram = median_filter(S_db, size=(3, 3))

    def compute_demon(self, demon_low=5, demon_high=200):
        y_bp = self._bandpass_filter(demon_low, demon_high)

        envelope = np.abs(signal.hilbert(y_bp))

        spectrum = np.abs(np.fft.rfft(envelope))
        freqs = np.fft.rfftfreq(len(envelope), 1 / self.sr)

        self.demon_freqs = freqs
        self.demon_spectrum = spectrum

    def plot_lofar(self):
        plt.figure(figsize=(10, 4))
        librosa.display.specshow(
            self.lofar_spectrogram,
            sr=self.sr,
            x_axis="time",
            y_axis="hz"
        )
        plt.colorbar(label="dB")
        plt.title("LOFAR Spectrogram")
        plt.tight_layout()
        plt.show()

    def plot_demon(self):
        plt.figure(figsize=(8, 4))
        plt.plot(self.demon_freqs, self.demon_spectrum)
        plt.xlim(0, 200)
        plt.xlabel("Frequency (Hz)")
        plt.ylabel("Amplitude")
        plt.title("DEMON Spectrum")
        plt.tight_layout()
        plt.show()


analyzer = LofarDemonAnalyzer("hydrophone.wav")

analyzer.load_audio()
analyzer.auto_select_band()

analyzer.compute_lofar()
analyzer.compute_demon()

analyzer.plot_lofar()
analyzer.plot_demon()

</code></pre>
    </section>

    <footer>
        © 2025 Bluuey UI – WAV Analyzer Documentation
    </footer>

</div>
<!-- Link to JavaScript --> <script src="script.js"></script>
</body>
</html>
